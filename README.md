# ğŸ“Š Financial Stock Analysis using LlamaIndex

## ğŸ“Œ Overview
This project leverages **LlamaIndex** to build a **GPT-powered vector store index** for analyzing stock-related articles. It integrates **OpenAI's GPT API** to create an index from documents stored in the `articles` directory, enabling efficient retrieval and analysis.

## ğŸš€ Features
- **Automated Document Parsing:** Reads and indexes stock analysis articles.
- **OpenAI GPT Integration:** Uses OpenAI's API for intelligent stock insights.
- **Vector Store Indexing:** Stores data for fast and efficient querying.
- **Persistent Storage:** Saves indexed data for future use.
- **Streamlit Dashboard:** Interactive UI for financial analysis.

## ğŸ› ï¸ Technology Used
- **LlamaIndex**
- **OpenAI GPT-4**
- **Streamlit**

ğŸ“Œ **Note:** Use Python version **3.8 or later**.

## ğŸ“‚ Project Structure
```
GENAI_Stock_Analysis_LlamaIndex/
â”‚-- .env                        # Environment variables (API keys, etc.)
â”‚-- articles/                    # Directory for input documents
â”‚-- storage/                     # Indexed data storage
â”‚-- src/
â”‚   â”‚-- fetch_data.py           # Script to fetch and extract articles
â”‚   â”‚-- generate_index.py       # Script to create the vector store index
â”‚-- requirements.txt             # Required Python packages
â”‚-- README.md                    # Documentation
â”‚-- app.py                       # Streamlit application
â”‚-- Dockerfile                   # Docker container configuration
```

## ğŸš€ How to Run?
### 1ï¸âƒ£ Clone the Repository
```bash
git clone "repository"
cd GENAI_Stock_Analysis_LlamaIndex
```

### 2ï¸âƒ£ Create a Conda Environment
```bash
conda create -n finance python=3.8 -y
conda activate finance
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Download and Extract Articles
```python
import os
import urllib.request as request
import zipfile

data_url = "https://github.com/entbappy/Branching-tutorial/raw/master/articles.zip"

def download_and_extract():
    zip_path = "articles.zip"
    request.urlretrieve(url=data_url, filename=zip_path)
    with zipfile.ZipFile(zip_path, "r") as zip_ref:
        zip_ref.extractall("articles")
    os.remove(zip_path)

download_and_extract()
```

### 5ï¸âƒ£ Run the Streamlit Application
```bash
streamlit run app.py
```
Now, open **http://localhost:8501** in your browser.

## ğŸ“¦ Running with Docker
### 1ï¸âƒ£ Build the Docker Image
```bash
docker build -t llamaindex-stock-analysis .
```

### 2ï¸âƒ£ Run the Docker Container
```bash
docker run -p 8501:8501 --env-file .env llamaindex-stock-analysis
```
Now, access the app at **http://localhost:8501**.

## ğŸ“ˆ Stock Symbols Used
```python
symbols = ['MSFT', 'NVDA', 'GOOG', 'META', 'AAPL', 'TSM']
```

## ğŸ” Troubleshooting
### âš ï¸ "unzip is not recognized as an internal or external command"
âœ… Fix: Use `zipfile` for extraction instead of `unzip` (already handled in the script).

### âš ï¸ "OPENAI_API_KEY is None"
âœ… Fix: Ensure your `.env` file exists and contains the correct API key. Restart your terminal if needed.

## ğŸ† Acknowledgments
- [LlamaIndex](https://gpt-index.readthedocs.io/en/latest/) for efficient document indexing.
- [OpenAI](https://openai.com) for GPT-powered insights.



